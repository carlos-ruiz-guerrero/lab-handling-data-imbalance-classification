import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.utils import resample
import numpy as np

# Load the dataset
churnData = pd.read_csv('Customer-Churn (1).csv')

# Convert 'TotalCharges' to numeric and handle missing values
churnData['TotalCharges'] = pd.to_numeric(churnData['TotalCharges'], errors='coerce')
churnData['TotalCharges'].fillna(churnData['TotalCharges'].mean(), inplace=True)

# Convert 'Churn' to numeric
churnData['Churn'] = churnData['Churn'].map({'Yes': 1, 'No': 0})

# Define features and target
features = ['tenure', 'SeniorCitizen', 'MonthlyCharges', 'TotalCharges']
target = 'Churn'
X = churnData[features]
y = churnData[target]

# Scale features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split data
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)

# Logistic Regression on imbalanced data
log_reg = LogisticRegression(random_state=42)
log_reg.fit(X_train, y_train)
y_pred = log_reg.predict(X_test)
accuracy_imbalanced = accuracy_score(y_test, y_pred)
print(f"Accuracy on imbalanced data: {accuracy_imbalanced:.4f}")

# Check class imbalance
print("\nClass distribution:")
print(churnData['Churn'].value_counts())

# Upsampling
majority = churnData[churnData.Churn == 0]
minority = churnData[churnData.Churn == 1]

minority_upsampled = resample(minority,
                                 replace=True,
                                 n_samples=len(majority),
                                 random_state=42)

upsampled_data = pd.concat([majority, minority_upsampled])
print("\nClass distribution after upsampling:")
print(upsampled_data.Churn.value_counts())

X_upsampled = upsampled_data[features]
y_upsampled = upsampled_data[target]
X_upsampled_scaled = scaler.fit_transform(X_upsampled)
X_train_up, X_test_up, y_train_up, y_test_up = train_test_split(X_upsampled_scaled, y_upsampled, test_size=0.3, random_state=42)

log_reg_upsampled = LogisticRegression(random_state=42)
log_reg_upsampled.fit(X_train_up, y_train_up)
y_pred_up = log_reg_upsampled.predict(X_test_up)
accuracy_upsampled = accuracy_score(y_test_up, y_pred_up)
print(f"Accuracy on upsampled data: {accuracy_upsampled:.4f}")

# Downsampling
majority_downsampled = resample(majority,
                                 replace=False,
                                 n_samples=len(minority),
                                 random_state=42)

downsampled_data = pd.concat([majority_downsampled, minority])
print("\nClass distribution after downsampling:")
print(downsampled_data.Churn.value_counts())

X_downsampled = downsampled_data[features]
y_downsampled = downsampled_data[target]
X_downsampled_scaled = scaler.fit_transform(X_downsampled)
X_train_down, X_test_down, y_train_down, y_test_down = train_test_split(X_downsampled_scaled, y_downsampled, test_size=0.3, random_state=42)

log_reg_downsampled = LogisticRegression(random_state=42)
log_reg_downsampled.fit(X_train_down, y_train_down)
y_pred_down = log_reg_downsampled.predict(X_test_down)
accuracy_downsampled = accuracy_score(y_test_down, y_pred_down)
print(f"Accuracy on downsampled data: {accuracy_downsampled:.4f}")
